# Knowledge Base Demo | Voiceflow
# Open AI GPT, Langchain, HNSWLib and Cheerio

This code utilizes Open AI GPT, Langchain, Redis Cache, and OpenSearch and Cheerio to fetch web content from URLs, create embeddings/vectors and save them in a local database. The knowledge base can then be used with GPT to answer questions.

## Quickstart Video
[![Watch the video](https://s3.amazonaws.com/com.voiceflow.studio/share/CleanShot-2023-03-17-at-14.03.29/CleanShot-2023-03-17-at-14.03.29.png)](https://www.loom.com/share/a4fccc7aac7d48548006570f6ac98576)


## Node.js
You need Node.js 18+ to run this code. You can download it here: https://nodejs.org/en/download/



## Table of Contents

1. [Getting Started](#getting-started)
2. [API Documentation](#api-documentation)
3. [Dependencies](#dependencies)

## Getting Started

### Installation

First, copy the `.env` file and set up required environment variables.

```bash
cp .env.example .env
```

To create the containers and install the required dependencies, run:

```bash
yarn build
```

This should create the following containers:
✔ Container redis (cache)
✔ Container unstructured (handle images, ppt, text, markdown)
✔ Container opensearch (search engine)
✔ Container opensearch-dashboards  (search engine dashboard)

OpenSearch dashboard can be accessed at http://localhost:5601

### Starting the Server

Start the server by running:

```bash
yarn start
```

The server will listen on the port specified in the `.env` file (default is 3000).

## API Documentation

### Check server health

```
GET /api/health
```

#### Response

- `200 OK` on success

```json
{
  "success": true,
  "message": "Server is healthy"
}
```

### Clear Redis cache

```
GET /api/clearcache
```

#### Response

- `200 OK` on success

```json
{
  "success": true,
  "message": "Cache cleared"
}
```


### Add content to OpenSearch

```
POST /api/add
```

#### Request

```json
{
  "url": "https://www.example.com/sitemap.xml", //* url of the sitemap
  "collection": "collection_name", //* name of the collection to populate
  "filter": "filter", // default to null - use to filter URL with this string (ex. "/blog/")
  "limit": 10, // default to null
  "chunkSize": 2000, // default to 2000
  "chunkOverlap": 250, // default to 250
  "sleep": 0 // For sitemap, time to wait between each URLs
}
```

#### Response

- `200 OK` on success

```json
{
  "response": "added",
  "collection": "collection_name"
}
```

### Delete a collection

```
DELETE /api/collection
```

#### Request

```json
{
  "collection": "collection_name", //* name of the collection to delete
}
```

#### Response

- `200 OK` on success

```json
{
  "success": true,
  "message": "{collection_name} has been deleted"
}
```

### Get a response using live webpage as context

```
POST /api/live
```

#### Request

```json
{
  "url": "https://www.example.com", //* url of the webpage
  "question": "Your question", //* the question to ask
  "temperature": 0 // default to 0
}
```

#### Response

- `200 OK` on success

```json
{
  "response": "response_text"
}
```

### Get a response using the vector store

```
POST /api/question
```

#### Request

```json
{
  "question": "your question", //* the question to ask
  "collection": "collection_name", //* name of the collection to search
  "model": "model_name", // default to gpt-3.5-turbo
  "k": 3, // default to 3 (max number of results to use)
  "temperature": 0, // default to 0
  "max_tokens": 400 // default to 400
}
```

#### Response

- `200 OK` on success

```json
{
  "response": "response_text",
  "sources": ["source1", "source2"]
}
```


## Using ngrok

To allow access to the app externally using the port set in the `.env` file, you can use ngrok. Follow the steps below:

1. Install ngrok: https://ngrok.com/download
2. Run `ngrok http <port>` in your terminal (replace `<port>` with the port set in your `.env` file)
3. Copy the ngrok URL generated by the command and use it in your Voiceflow Assistant API step.

This can be handy if you want to quickly test this in an API step within your Voiceflow Assistant.
